{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, ConfusionMatrixDisplay, auc, roc_auc_score, f1_score, confusion_matrix\n",
    "from sklearn import datasets\n",
    "from statistics import mean\n",
    "import includes.model as mod\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from includes.config import Config;\n",
    "import includes.model_functions as mf\n",
    "import time\n",
    "from itertools import combinations\n",
    "import random\n",
    "from graphviz import Digraph\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from datetime import datetime \n",
    "import os\n",
    "import argparse\n",
    "from itertools import count\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Example dataset with age, education, employment status, and income\n",
    "data_australia = {\n",
    "    'bachelors_count': [1000],\n",
    "    'tertiary_education': [100000],  \n",
    "    'highest_year_graduated': [45],  \n",
    "    'rate_of_mental_health': [1010]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data_australia)\n",
    "print(df)\n",
    "# Define features (X) and target (y)\n",
    "X = df[['bachelors_count', 'tertiary_education', 'highest_year_graduated']]\n",
    "y = df['rate_of_mental_health']\n",
    "\n",
    "# Initialize and train linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the coefficients for each feature\n",
    "# coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "\n",
    "# Display the coefficients\n",
    "print(\"Regression Coefficients:\")\n",
    "print(model.coef_)\n",
    "# print(coefficients)\n",
    "\n",
    "# Predictions (optional)\n",
    "data_england = {\n",
    "    'bachelors_count': [10],\n",
    "    'tertiary_education': [10000],\n",
    "    'highest_year_graduated': [3],\n",
    "    'rate_of_mental_health': [101]\n",
    "}\n",
    "df_predict = pd.DataFrame(data_england)\n",
    "X_test = df_predict[['bachelors_count', 'tertiary_education', 'highest_year_graduated']]\n",
    "y_test = df_predict['rate_of_mental_health']\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Predicted mental health:{y_pred}\")\n",
    "print(f\"True mental health:{y_test}\")\n",
    "print(f\"mse: {mean_squared_error(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([df, df_predict], ignore_index=True)\n",
    "correlation_matrix = new_df.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "Data must have: \n",
    "- target class = Y\n",
    "- features all non categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pen based digits\n",
    "config = Config(\"testing_datasets\")\n",
    "pen_based_recognition_of_handwritten_digits = fetch_ucirepo(id=81) \n",
    "filename = \"pen_based_classifier\"\n",
    "model_types = ['LogisticRegression']\n",
    "df = pen_based_recognition_of_handwritten_digits.data.original\n",
    "# print(df['Class'])\n",
    "# ecoli_data = ecoli_data.head(1000)\n",
    "df.rename({'Class': 'Y'}, axis=1, inplace=True)\n",
    "# df.to_csv(\"data/handwritten_digits.csv\")\n",
    "df\n",
    "# df = df.head(1000)\n",
    "# df['Y'], unique_strings = pd.factorize(df['class'])\n",
    "# ecoli_data['Sequence_numerical'], unique_seq_strings = pd.factorize(ecoli_data['Sequence'])\n",
    "# df.drop(['class', 'Sequence'], axis=1, inplace=True)\n",
    "# ecoli_data['Y'] = ecoli_data['encoded_Y']\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecoli details\n",
    "df = fetch_ucirepo(id=39) \n",
    "file_name = 'ecoli'\n",
    "model_types = ['LogisticRegression']\n",
    "df = df.data.original\n",
    "df.rename({'Class': 'Y'}, axis=1, inplace=True)\n",
    "# df.to_csv(\"data/beans_data.csv\")\n",
    "df = pd.read_csv(\"ecoli.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/ecoli.csv\")\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beans data\n",
    "file_name = \"beans_datasets\"\n",
    "config = Config(\"beans_datasets\")\n",
    "df = fetch_ucirepo(id=602)\n",
    "filename = \"beans_data\"\n",
    "model_types = ['LogisticRegression']\n",
    "df = df.data.original\n",
    "df.rename({'Class': 'Y'}, axis=1, inplace=True)\n",
    "# df.to_csv(\"data/beans_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letter recognition\n",
    "config = Config(\"letter_rec\")\n",
    "letter_recognition = fetch_ucirepo(id=59) \n",
    "letter_recognition_data = letter_recognition.data.original\n",
    "filename = \"letter_recognition\"\n",
    "# model_types = ['randomForest', 'LogisticRegression', 'xgboost']\n",
    "model_types = ['LogisticRegression']\n",
    "transform_label = LabelEncoder()\n",
    "# letter_recognition_data['lettr'] = transform_label.fit_transform(letter_recognition_data['lettr'])\n",
    "df = letter_recognition_data\n",
    "df.rename({'lettr': 'Y'}, axis=1, inplace=True)\n",
    "# df.to_csv(\"data/letter_recognition.csv\")\n",
    "# ecoli_data = abalone.data.original\n",
    "# df.to_csv(\"data/letter_recognition.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statlog\n",
    "statlog_shuttle = fetch_ucirepo(id=148) \n",
    "df = statlog_shuttle.data.original\n",
    "df.rename({'class': 'Y'}, axis=1, inplace=True)\n",
    "df.to_csv(\"data/statlog_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Room Occupany\n",
    "df = fetch_ucirepo(id=864) \n",
    "df = df.data.original\n",
    "df.rename({'Room_Occupancy_Count': 'Y'}, axis=1, inplace=True)\n",
    "# df\n",
    "df = mf.one_hot_encode(df, \"Date\")\n",
    "df = mf.one_hot_encode(df, \"Time\")\n",
    "# df.to_csv(\"data/room_occupancy_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast data\n",
    "config = Config(\"yeast\")\n",
    "filename = \"yeast\"\n",
    "yeast = fetch_ucirepo(id=110) \n",
    "df = yeast.data.original\n",
    "# transform_label = LabelEncoder()\n",
    "df.drop('Sequence_Name', axis=1, inplace=True)\n",
    "df.rename({'localization_site': 'Y'}, axis=1, inplace=True)\n",
    "# pre_transform_categories = tuple(df['Y'].unique())\n",
    "# df['Y'] = transform_label.fit_transform(df['Y'])\n",
    "# mapped_categories = dict(zip(pre_transform_categories, transform_label.transform(pre_transform_categories)))\n",
    "# config.log.info(f\"mapped categories: {mapped_categories}\")\n",
    "# df = mf.one_hot_encode(df, \"Sequence_Name\")\n",
    "# df.to_csv(\"data/yeast.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vowel data\n",
    "config = Config(\"beans_datasets\")\n",
    "df = fetch_ucirepo(id=602)\n",
    "df = df.data.original\n",
    "df.rename({'Class': 'Y'}, axis=1, inplace=True)\n",
    "# df.to_csv(\"data/beans_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# satimage\n",
    "df = fetch_ucirepo(id=146)\n",
    "df = df.data.original\n",
    "config =  Config(\"satimage\")\n",
    "filename = 'satimage'\n",
    "df.rename({'class': 'Y'}, axis=1, inplace=True)\n",
    "# df.to_csv(\"data/beans_data.csv\")\n",
    "# df.to_csv(\"data/satimage.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glass data\n",
    "config = Config(\"glass_datasets\")\n",
    "filename = \"glass_datasets\"\n",
    "df = fetch_ucirepo(id=42)\n",
    "df = df.data.original\n",
    "df.drop('Id_number', axis=1, inplace=True)\n",
    "df.rename({'Type_of_glass': 'Y'}, axis=1, inplace=True)\n",
    "# df.to_csv(\"data/glass_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_recognition = fetch_ucirepo(id=59) \n",
    "letter_recognition_data = letter_recognition.data.original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abalone\n",
    "config = Config(\"testing_datasets\")\n",
    "filename = \"abalone_classifier\"\n",
    "abalone = pd.read_csv(\"data/abalone.csv\")\n",
    "abalone.rename({'Rings': 'Y'}, axis=1, inplace=True)\n",
    "df = mf.one_hot_encode(abalone, \"Sex\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image segmentation\n",
    "df = fetch_ucirepo(id=147) \n",
    "df = df.data.original\n",
    "df.rename({'class': 'Y'}, axis=1, inplace=True)\n",
    "# df.to_csv(\"data/image_segment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covertype data\n",
    "df = fetch_ucirepo(id=31) \n",
    "df = df.data.original\n",
    "df.rename({'Cover_Type': 'Y'}, axis=1, inplace=True)\n",
    "df.to_csv(\"data/cover_type.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Car evaluation data\n",
    "df = fetch_ucirepo(id=19) \n",
    "df = df.data.original\n",
    "df = mf.one_hot_encode(df, \"buying\")\n",
    "df = mf.one_hot_encode(df, \"maint\")\n",
    "df = mf.one_hot_encode(df, \"doors\")\n",
    "df = mf.one_hot_encode(df, \"persons\")\n",
    "df = mf.one_hot_encode(df, \"lug_boot\")\n",
    "df = mf.one_hot_encode(df, \"safety\")\n",
    "df.rename({'class': 'Y'}, axis=1, inplace=True)\n",
    "df.to_csv(\"data/car_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pageblocks data\n",
    "df = fetch_ucirepo(id=78) \n",
    "df = df.data.original\n",
    "df.rename({'class': 'Y'}, axis=1, inplace=True)\n",
    "filename = 'pageblocks'\n",
    "# df.to_csv(\"data/pageblocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optdigits data\n",
    "df = fetch_ucirepo(id=80) \n",
    "df = df.data.original\n",
    "df.rename({'class': 'Y'}, axis=1, inplace=True)\n",
    "df.to_csv(\"data/optdigits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bike sharing data\n",
    "df = fetch_ucirepo(id=275) \n",
    "df = df.data.original\n",
    "df.rename({'cnt': 'Y'}, axis=1, inplace=True)\n",
    "# df.to_csv(\"data/bike_sharing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfeat-factors data\n",
    "filename = \"mfeat-factors\" \n",
    "df = pd.read_csv(\"data/mfeat/mfeat-fac\", delim_whitespace=True, header=None)\n",
    "y_column = []\n",
    "for i in range(10):\n",
    "    y_column.extend([i] * 200)\n",
    "\n",
    "# Add the 'Y' column to the DataFrame\n",
    "df['Y'] = y_column\n",
    "# df.to_csv(\"data/mfeat-factors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfeat-fourier data\n",
    "filename = 'mfeat-fourier'\n",
    "config = Config(filename)\n",
    "df = pd.read_csv(\"data/mfeat/mfeat-fou\", delim_whitespace=True, header=None)\n",
    "y_column = []\n",
    "for i in range(10):\n",
    "    y_column.extend([i] * 200)\n",
    "\n",
    "# Add the 'Y' column to the DataFrame\n",
    "df['Y'] = y_column\n",
    "# df.to_csv(\"data/mfeat-fouriers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfeat-karhunen data\n",
    "df = pd.read_csv(\"data/mfeat/mfeat-kar\", delim_whitespace=True, header=None)\n",
    "y_column = []\n",
    "for i in range(10):\n",
    "    y_column.extend([i] * 200)\n",
    "\n",
    "# Add the 'Y' column to the DataFrame\n",
    "df['Y'] = y_column\n",
    "df.to_csv(\"data/mfeat-karhunen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfeat-pixel data\n",
    "df = pd.read_csv(\"data/mfeat/mfeat-pix\", delim_whitespace=True, header=None)\n",
    "y_column = []\n",
    "for i in range(10):\n",
    "    y_column.extend([i] * 200)\n",
    "\n",
    "# Add the 'Y' column to the DataFrame\n",
    "df['Y'] = y_column\n",
    "df.to_csv(\"data/mfeat-pixel.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfeat-morphological data\n",
    "df = pd.read_csv(\"data/mfeat/mfeat-mor\", delim_whitespace=True, header=None)\n",
    "y_column = []\n",
    "for i in range(10):\n",
    "    y_column.extend([i] * 200)\n",
    "\n",
    "# Add the 'Y' column to the DataFrame\n",
    "df['Y'] = y_column\n",
    "# df.to_csv(\"data/mfeat-morphological.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mfeat-zernlike data\n",
    "df = pd.read_csv(\"data/mfeat/mfeat-zer\", delim_whitespace=True, header=None)\n",
    "filename = \"mfeat-zernlike\"\n",
    "y_column = []\n",
    "for i in range(10):\n",
    "    y_column.extend([i] * 200)\n",
    "\n",
    "# Add the 'Y' column to the DataFrame\n",
    "df['Y'] = y_column\n",
    "# df.to_csv(\"data/mfeat-zernlike.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoo data\n",
    "df = fetch_ucirepo(id=111) \n",
    "df = df.data.original\n",
    "df.rename({'type': 'Y'}, axis=1, inplace=True)\n",
    "filename = 'zoo'\n",
    "# df.fillna(-1)\n",
    "df.drop('animal_name', axis=1, inplace=True)\n",
    "# df.to_csv(\"data/zoo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('Y').size().reset_index(name='counts')\n",
    "# df = df.loc[(df['Y'] > 4) & (df['Y'] < 17)]\n",
    "# grouped_df = df.groupby('Y').size().reset_index(name='counts')\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/abalone_culled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine quality dataset\n",
    "df = fetch_ucirepo(id=186) \n",
    "df = df.data.original\n",
    "df.rename({'quality': 'Y'}, axis=1, inplace=True)\n",
    "df = mf.one_hot_encode(df, \"color\")\n",
    "df.to_csv(\"data/wine_quality_data.csv\")\n",
    "filename = \"wine_quality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breast cancer\n",
    "df = fetch_ucirepo(id=14)\n",
    "df = df.data.original\n",
    "df.rename({'Class': 'Y'}, axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run my ML model\n",
    "# if not transform_label:\n",
    "#     transform_label = None\n",
    "if not filename:\n",
    "    filename = 'unsure_dataset'\n",
    "\n",
    "config = Config(filename)\n",
    "transform_label = mf.map_categorical_target(config, df)\n",
    "model_types = ['randomForest', 'LogisticRegression','xgboost']\n",
    "model_types = ['SVM']\n",
    "# model_types = ['svm']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df['Y'], stratify=df['Y'], test_size=0.2, random_state=42)\n",
    "score_type = 'accuracy'\n",
    "# categories = tuple((0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\n",
    "categories = tuple(df['Y'].unique())\n",
    "best_tree = mf.stepwise_tree_finder(config, categories, X_train, [], {}, model_types=model_types, score_type=score_type)\n",
    "config.log.info('Finished stepwise tree finder.')\n",
    "model_strucs = list(best_tree.keys())\n",
    "tree_types = list(best_tree.values())\n",
    "print(model_strucs)\n",
    "print(tree_types)\n",
    "best_trained_model = mf.build_best_tree(config, X_test, X_train, y_test, score_type, tree_types, model_strucs, categories, transform_label = transform_label)\n",
    "mf.graph_model(config, best_trained_model, filename, transform_label, model_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [1,2,3,4,5,6,7]\n",
    "size_list = len(list1) - 1\n",
    "rev = []\n",
    "for i in range(len(list1)):\n",
    "    rev.append(list1[size_list - i])\n",
    "# print(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate the server run\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df['Y'], test_size=0.2, random_state=42)\n",
    "model_strucs = [((0, 3, 8), (1, 2, 5, 4, 6, 7, 9)), ((0,), (8, 3)), ((3,), (8,)), ((2,), (1, 5, 4, 6, 7, 9)),  ((5,), (1, 4, 6, 7, 9)), ((7, 1, 4), (6, 9)), ((6,), (9,)), ((7,), (1, 4)), ((1,), (4,))]\n",
    "tree_types = ['LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression']\n",
    "tree_types = 'LogisticRegression'\n",
    "best_trained_model = mf.build_best_tree(config, X_test, X_train, y_test, score_type, tree_types, model_strucs, categories, transform_label = transform_label)\n",
    "mf.graph_model(config, best_trained_model, filename, transform_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicate the server run\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df['Y'], test_size=0.2, random_state=42)\n",
    "model_strucs = [((0, 3, 8), (1, 2, 5, 4, 6, 7, 9)), ((0,), (8, 3)), ((3,), (8,)), ((2,), (1, 5, 4, 6, 7, 9)),  ((5,), (1, 4, 6, 7, 9)), ((7, 1, 4), (6, 9)), ((6,), (9,)), ((7,), (1, 4)), ((1,), (4,))]\n",
    "tree_types = ['LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression']\n",
    "tree_types = 'LogisticRegression'\n",
    "best_trained_model = mf.build_best_tree(config, X_test, X_train, y_test, score_type, tree_types, model_strucs, categories, transform_label = transform_label)\n",
    "mf.graph_model(config, best_trained_model, filename, transform_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_strucs = [((0, 3, 8), (1, 2, 5, 4, 6, 7, 9)), ((0,), (8, 3)), ((3,), (8,)), ((2,), (1, 5, 4, 6, 7, 9)),  ((5,), (1, 4, 6, 7, 9)), ((7, 1, 4), (6, 9)), ((6,), (9,)), ((7,), (1, 4)), ((1,), (4,))]\n",
    "tree_types = ['LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression', 'LogisticRegression']\n",
    "tree_types = 'LogisticRegression'\n",
    "transform_label = mf.map_categorical_target(config, df)\n",
    "built_mods = mf.build_single_models(config, best_tree, X_train, score_type=score_type, train_type=tree_types)\n",
    "mf.test_single_models(built_mods, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform_label = mf.map_categorical_target(config, df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, df['Y'], stratify=df['Y'], test_size=0.2, random_state=42)\n",
    "score_type = 'accuracy'\n",
    "categories = tuple(df['Y'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_label = mf.map_categorical_target(config, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = tuple((19, 13, 6, 18, 1, 0, 9, 23, 14, 17, 5, 2, 7, 15, 4, 16, 20, 10, 25))\n",
    "best_tree = mf.stepwise_tree_finder(config, categories, X_train, X_test, {}, model_types=model_types, score_type=score_type)\n",
    "config.log.info('Finished stepwise tree finder.')\n",
    "model_strucs = list(best_tree.keys())\n",
    "tree_types = list(best_tree.values())\n",
    "print(model_strucs)\n",
    "print(tree_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used = transform_label.transform(['M', 'W', 'V', 'Y', 'I', 'L'])\n",
    "used = transform_label.transform(['Z', 'S', 'M', 'W', 'V', 'Y', 'I', 'L'])\n",
    "left = transform_label.transform(['E', 'D', 'B', 'P', 'R', 'F'])\n",
    "transform_label.transform(['C', 'G'])\n",
    "transform_label.transform(['E', 'D', 'B', 'P', 'R', 'F'])\n",
    "transform_label.transform(['E', 'D', 'B', 'P', 'R', 'F'])\n",
    "transform_label.transform(['I', 'T', 'L'])\n",
    "transform_label.transform(['C', 'G'])\n",
    "transform_label.transform(['I', 'L'])\n",
    "right = tuple(x for x in categories if x not in left and x not in used) \n",
    "built_mods = mf.build_single_models(config, [[tuple(left), tuple(right)]], X_train, score_type='accuracy', train_type='LogisticRegression')\n",
    "print(mf.test_single_models(built_mods, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(used)\n",
    "tuple(transform_label.transform(['I'])), tuple(transform_label.transform(['L']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_label.inverse_transform((16, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a tree for letters\n",
    "manual_tree=[ \n",
    "    [tuple(transform_label.transform(['M', 'W'])), tuple(transform_label.transform(['T', 'I', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'L', 'P', 'E', 'V', 'Y', 'Q', 'U', 'K', 'Z']))], \n",
    "    [tuple(transform_label.transform(['M'])), tuple(transform_label.transform(['W']))],\n",
    "    [tuple(transform_label.transform(['V', 'Y'])), tuple(transform_label.transform(['T', 'I', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'L', 'P', 'E', 'Q', 'U', 'K', 'Z']))], \n",
    "    [tuple(transform_label.transform(['V'])), tuple(transform_label.transform(['Y']))], \n",
    "    [tuple(transform_label.transform(['I', 'L'])), tuple(transform_label.transform(['T', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K', 'Z']))],\n",
    "    [tuple(transform_label.transform(['I'])), tuple(transform_label.transform(['L']))], \n",
    "    [tuple(transform_label.transform(['Z', 'S'])), tuple(transform_label.transform(['T', 'D', 'N', 'G', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['Z'])), tuple(transform_label.transform(['S']))], \n",
    "    [tuple(transform_label.transform(['D'])), tuple(transform_label.transform(['T', 'N', 'G', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))], \n",
    "    [tuple(transform_label.transform(['J'])), tuple(transform_label.transform(['T', 'N', 'G', 'B', 'A', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))], \n",
    "    [tuple(transform_label.transform(['A'])), tuple(transform_label.transform(['T', 'N', 'G', 'B', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['T'])), tuple(transform_label.transform(['N', 'G', 'B', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['N'])), tuple(transform_label.transform(['G', 'B', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['P', 'F'])), tuple(transform_label.transform(['G', 'B', 'X', 'O', 'R', 'C', 'H', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['P'])), tuple(transform_label.transform(['F']))], \n",
    "    [tuple(transform_label.transform(['U'])), tuple(transform_label.transform(['G', 'B', 'X', 'O', 'R', 'C', 'H', 'E', 'Q', 'K']))],\n",
    "    [tuple(transform_label.transform(['X'])), tuple(transform_label.transform(['G', 'B', 'O', 'R', 'C', 'H', 'E', 'Q', 'K']))],\n",
    "    [tuple(transform_label.transform(['K'])), tuple(transform_label.transform(['G', 'B', 'O', 'R', 'C', 'H', 'E', 'Q']))],\n",
    "    [tuple(transform_label.transform(['C', 'E'])), tuple(transform_label.transform(['G', 'B', 'O', 'R', 'H', 'Q']))],\n",
    "    [tuple(transform_label.transform(['C'])), tuple(transform_label.transform(['E']))], \n",
    "    [tuple(transform_label.transform(['O', 'H'])), tuple(transform_label.transform(['G', 'B', 'R', 'Q']))],\n",
    "    [tuple(transform_label.transform(['O'])), tuple(transform_label.transform(['H']))], \n",
    "    [tuple(transform_label.transform(['Q', 'G'])), tuple(transform_label.transform(['B', 'R']))],\n",
    "    [tuple(transform_label.transform(['Q'])), tuple(transform_label.transform(['G']))], \n",
    "    [tuple(transform_label.transform(['B'])), tuple(transform_label.transform(['R']))]\n",
    "]\n",
    "categories = tuple(df['Y'].unique())\n",
    "tree_types = 'LogisticRegression'\n",
    "score_type = 'accuracy'\n",
    "# built_mods = mf.build_single_models(config, manual_tree, X_train, score_type='accuracy', train_type='LogisticRegression')\n",
    "# print(mf.test_single_models(built_mods, X_test))\n",
    "best_trained_model = mf.build_best_tree(config, X_test, X_train, y_test, score_type, tree_types, manual_tree, categories, transform_label = transform_label)\n",
    "mf.graph_model(config, best_trained_model, filename, transform_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a tree for letters\n",
    "manual_tree=[ \n",
    "    [tuple(transform_label.transform(['M', 'W'])), tuple(transform_label.transform(['T', 'I', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'L', 'P', 'E', 'V', 'Y', 'Q', 'U', 'K', 'Z']))], \n",
    "    [tuple(transform_label.transform(['M'])), tuple(transform_label.transform(['W']))],\n",
    "    [tuple(transform_label.transform(['V', 'Y'])), tuple(transform_label.transform(['T', 'I', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'L', 'P', 'E', 'Q', 'U', 'K', 'Z']))], \n",
    "    [tuple(transform_label.transform(['V'])), tuple(transform_label.transform(['Y']))], \n",
    "    [tuple(transform_label.transform(['I', 'L'])), tuple(transform_label.transform(['T', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K', 'Z']))],\n",
    "    [tuple(transform_label.transform(['E', 'D', 'B', 'P', 'R', 'F'])), tuple(transform_label.transform(['T', 'D', 'N', 'G', 'S', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K', 'Z']))],\n",
    "    [tuple(transform_label.transform(['I'])), tuple(transform_label.transform(['L']))], \n",
    "    [tuple(transform_label.transform(['Z', 'S'])), tuple(transform_label.transform(['T', 'D', 'N', 'G', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['Z'])), tuple(transform_label.transform(['S']))], \n",
    "    [tuple(transform_label.transform(['D'])), tuple(transform_label.transform(['T', 'N', 'G', 'B', 'A', 'J', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))], \n",
    "    [tuple(transform_label.transform(['J'])), tuple(transform_label.transform(['T', 'N', 'G', 'B', 'A', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))], \n",
    "    [tuple(transform_label.transform(['A'])), tuple(transform_label.transform(['T', 'N', 'G', 'B', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['T'])), tuple(transform_label.transform(['N', 'G', 'B', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['N'])), tuple(transform_label.transform(['G', 'B', 'X', 'O', 'R', 'F', 'C', 'H', 'P', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['P', 'F'])), tuple(transform_label.transform(['G', 'B', 'X', 'O', 'R', 'C', 'H', 'E', 'Q', 'U', 'K']))],\n",
    "    [tuple(transform_label.transform(['P'])), tuple(transform_label.transform(['F']))], \n",
    "    [tuple(transform_label.transform(['U'])), tuple(transform_label.transform(['G', 'B', 'X', 'O', 'R', 'C', 'H', 'E', 'Q', 'K']))],\n",
    "    [tuple(transform_label.transform(['X'])), tuple(transform_label.transform(['G', 'B', 'O', 'R', 'C', 'H', 'E', 'Q', 'K']))],\n",
    "    [tuple(transform_label.transform(['K'])), tuple(transform_label.transform(['G', 'B', 'O', 'R', 'C', 'H', 'E', 'Q']))],\n",
    "    [tuple(transform_label.transform(['C', 'E'])), tuple(transform_label.transform(['G', 'B', 'O', 'R', 'H', 'Q']))],\n",
    "    [tuple(transform_label.transform(['C'])), tuple(transform_label.transform(['E']))], \n",
    "    [tuple(transform_label.transform(['O', 'H'])), tuple(transform_label.transform(['G', 'B', 'R', 'Q']))],\n",
    "    [tuple(transform_label.transform(['O'])), tuple(transform_label.transform(['H']))], \n",
    "    [tuple(transform_label.transform(['Q', 'G'])), tuple(transform_label.transform(['B', 'R']))],\n",
    "    [tuple(transform_label.transform(['Q'])), tuple(transform_label.transform(['G']))], \n",
    "    [tuple(transform_label.transform(['B'])), tuple(transform_label.transform(['R']))]\n",
    "]\n",
    "categories = tuple(df['Y'].unique())\n",
    "tree_types = 'LogisticRegression'\n",
    "score_type = 'accuracy'\n",
    "# built_mods = mf.build_single_models(config, manual_tree, X_train, score_type='accuracy', train_type='LogisticRegression')\n",
    "# print(mf.test_single_models(built_mods, X_test))\n",
    "best_trained_model = mf.build_best_tree(config, X_test, X_train, y_test, score_type, tree_types, manual_tree, categories, transform_label = transform_label)\n",
    "mf.graph_model(config, best_trained_model, filename, transform_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a tree for letters\n",
    "manual_tree = [ \n",
    "    ((12, 22), (19, 8, 3, 13, 6, 18, 1, 0, 9, 23, 14, 17, 5, 2, 7, 11, 15, 4, 21, 24, 16, 20, 10, 25)), \n",
    "    ((12,), (22,)),  \n",
    "    ((21, 24), (19, 8, 3, 13, 6, 18, 1, 0, 9, 23, 14, 17, 5, 2, 7, 11, 15, 4, 16, 20, 10, 25)), \n",
    "    ((21,), (24,)), \n",
    "    ((8, 11), (19, 3, 13, 6, 18, 1, 0, 9, 23, 14, 17, 5, 2, 7, 15, 4, 16, 20, 10, 25)), \n",
    "    ((8,), (11,)), \n",
    "    ((3,), (19, 13, 6, 18, 1, 0, 9, 23, 14, 17, 5, 2, 7, 15, 4, 16, 20, 10, 25)), \n",
    "    ((9,), (19, 13, 6, 18, 1, 0, 23, 14, 17, 5, 2, 7, 15, 4, 16, 20, 10, 25)), \n",
    "    ((0,), (19, 13, 6, 18, 1, 23, 14, 17, 5, 2, 7, 15, 4, 16, 20, 10, 25)), \n",
    "    ((19,), (13, 6, 18, 1, 23, 14, 17, 5, 2, 7, 15, 4, 16, 20, 10, 25)), \n",
    "    ((13,), (6, 18, 1, 23, 14, 17, 5, 2, 7, 15, 4, 16, 20, 10, 25)), \n",
    "    ((15, 5), (6, 18, 1, 23, 14, 17, 2, 7, 4, 16, 20, 10, 25)), \n",
    "    ((15,), (5,)), \n",
    "    ((20,), (6, 18, 1, 23, 14, 17, 2, 7, 4, 16, 10, 25)), \n",
    "    ((25,), (6, 18, 1, 23, 14, 17, 2, 7, 4, 16, 10)), \n",
    "    ((23,), (6, 18, 1, 14, 17, 2, 7, 4, 16, 10)), \n",
    "    ((10,), (6, 18, 1, 14, 17, 2, 7, 4, 16)), \n",
    "    ((2, 4), (6, 18, 1, 14, 17, 7, 16)), \n",
    "    ((2,), (4,)), \n",
    "    ((18,), (6, 1, 14, 17, 7, 16)), \n",
    "    ((1, 17, 6, 16), (14, 7)), \n",
    "    ((16, 6), (1, 17)), \n",
    "    ((16,), (6,)), \n",
    "    ((1,), (17,)), \n",
    "    ((14,), (7,)) \n",
    "]\n",
    "\n",
    "best_tree = manual_tree\n",
    "categories = tuple(df['Y'].unique())\n",
    "tree_types = 'LogisticRegression'\n",
    "score_type = 'accuracy'\n",
    "\n",
    "# built_mods = mf.build_single_models(config, manual_tree, X_train, score_type='accuracy', train_type='LogisticRegression')\n",
    "# print(mf.test_single_models(built_mods, X_test))\n",
    "# built_mods = mf.build_single_models(config, best_tree, X_train, score_type=score_type, train_type=tree_types)\n",
    "# mf.test_single_models(built_mods, X_test)\n",
    "# built_mods = list(built_mods.values())\n",
    "# config.log.info(f'Best models are {built_mods}')\n",
    "\n",
    "# mf.build_single_models(config, best_tree, X_train, score_type=score_type, train_type=tree_types)\n",
    "best_trained_model = mf.build_best_tree(config, X_test, X_train, y_test, score_type, tree_types, manual_tree, categories, transform_label = transform_label)\n",
    "mf.graph_model(config, best_trained_model, filename, transform_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right = categories - left\n",
    "built_mods = mf.build_single_models(config, [[tuple(left), right]], X_train, score_type='accuracy', train_type='LogisticRegression')\n",
    "print(mf.test_single_models(built_mods, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trained_model = mf.build_best_tree(config, X_test, X_train, y_test, score_type, tree_types, model_strucs, categories, transform_label = transform_label)\n",
    "mf.graph_model(config, best_trained_model, filename, transform_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_trained_model = mf.build_best_tree(config, X_test, X_train, y_test, score_type, tree_types, model_strucs, categories, transform_label = transform_label) \n",
    "filename = \"yeast\"\n",
    "mf.graph_model(config, best_trained_model, filename, transform_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_tree)\n",
    "model_strucs = list(best_tree.keys())\n",
    "tree_types = list(best_tree.values())\n",
    "score_type = 'accuracy'\n",
    "best_trained_model = mf.build_best_tree(config, X_test, X_train, y_test, score_type, tree_types, model_strucs, categories, target_conversion = transform_label)\n",
    "\n",
    "# built_mods = mf.build_single_models(config, best_tree, X_train, score_type=score_type, train_type=tree_types)\n",
    "# print(built_mods)\n",
    "# mf.test_single_models(built_mods, X_test)\n",
    "\n",
    "# mf.graph_model(config, best_trained_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.graph_model(config, best_trained_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run with Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with multinomial logisitc regression\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=Y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix with labels\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with random forest\n",
    "# df.drop(df.columns[0], axis=1, inplace=True)\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.10f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with SVM OVO\n",
    "# df.drop(df.columns[0], axis=1, inplace=True)\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=43)\n",
    "model = model = make_pipeline(StandardScaler(), svm.SVC(decision_function_shape='ovo'))\n",
    "# model = svm.SVC(decision_function_shape='ovo')\n",
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with SVM OVR\n",
    "# df.drop(df.columns[0], axis=1, inplace=True)\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=43)\n",
    "model = model = make_pipeline(StandardScaler(), svm.SVC(decision_function_shape='ovr'))\n",
    "# model = svm.SVC(decision_function_shape='ovo')\n",
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM OVO proper implementation\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=43)\n",
    "model = model = make_pipeline(StandardScaler(), svm.SVC())\n",
    "model = OneVsOneClassifier(model)\n",
    "# model = svm.SVC(decision_function_shape='ovo')\n",
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM OVR proper implementation \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=43)\n",
    "model = model = make_pipeline(StandardScaler(), svm.SVC(decision_function_shape='ovr'))\n",
    "model = OneVsRestClassifier(model)\n",
    "# model = svm.SVC(decision_function_shape='ovo')\n",
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with xgboost OVO\n",
    "transform_label = mf.map_categorical_target(config, df)\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=43)\n",
    "model = xgb.XGBClassifier(n_jobs = -1, objective=\"binary:logistic\")\n",
    "model = OneVsOneClassifier(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.10f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with xgboost OVR\n",
    "transform_label = mf.map_categorical_target(config, df)\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=43)\n",
    "model = xgb.XGBClassifier(n_jobs = -1, objective=\"binary:logistic\")\n",
    "model = OneVsRestClassifier(model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.10f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with knn\n",
    "# transform_label = mf.map_categorical_target(config, df)\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {'n_neighbors': range(1, 31)}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "knn = KNeighborsClassifier()\n",
    "model = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.10f}')\n",
    "print(f'number of neighbours: {1}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with LDA\n",
    "transform_label = mf.map_categorical_target(config, df)\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=42)\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.10f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# transform_label = mf.map_categorical_target(config, df)\n",
    "Y = df['Y']\n",
    "df_x = df.drop('Y', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Y, stratify=df['Y'], test_size=0.2, random_state=42)\n",
    "model = make_pipeline(StandardScaler(), MLPClassifier(max_iter = 400))\n",
    "# model = MLPClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.10f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://github.com/v-melnikov/nested-dichotomies/blob/master/nd/BBoK.py from paper\n",
    "# paper is \"On the Effectiveness of Heuristics for Learning Nested Dichotomies: An Empirical Analysis\"\n",
    "\n",
    "def generate_bbok_split(enc):\n",
    "    c = len(bin(enc)[2:])\n",
    "    a = np.arange(c, dtype=int)\n",
    "    rc = a[(1 << a & enc).astype(bool)]\n",
    "    if len(rc) == 1:\n",
    "        return (1 << rc[0], 0)\n",
    "\n",
    "    sub_id = np.random.randint(1, np.power(2, len(rc) - 1))\n",
    "    mask = format(sub_id, 'b').zfill(len(rc))\n",
    "    mask = np.array(list(mask), dtype=int)\n",
    "    c1_group = rc[mask.astype(bool)]\n",
    "    c2_group = np.setdiff1d(rc, c1_group)\n",
    "\n",
    "    return (np.sum(1 << np.array(c1_group)), np.sum(1 << np.array(c2_group)))\n",
    "\n",
    "def decode_split(split, labels):\n",
    "    \"\"\"Convert binary splits into subsets of elements.\"\"\"\n",
    "    c1_bin, c2_bin = split\n",
    "    c1 = [i for i in labels if (1 << i) & c1_bin]\n",
    "    c2 = [i for i in labels if (1 << i) & c2_bin]\n",
    "    return (tuple(c1), tuple(c2))\n",
    "\n",
    "def generate(n, labels=None, seed=42):\n",
    "    ds = []  # dichotomies\n",
    "    s = []  # stack\n",
    "    if labels is None:\n",
    "        labels = np.arange(n, dtype=int)\n",
    "    rc = np.sum([1 << i for i in labels])\n",
    "    np.random.seed(seed)\n",
    "    root_split = generate_bbok_split(rc)\n",
    "    s.append(root_split)\n",
    "    while len(s) != 0:\n",
    "        split = s.pop()\n",
    "        ds.append(split)\n",
    "        if split[1] != 0:\n",
    "            s.append(generate_bbok_split(split[1]))\n",
    "            s.append(generate_bbok_split(split[0]))\n",
    "        else:\n",
    "            ds.pop()\n",
    "    decoded_splits = [decode_split(split, labels) for split in ds]\n",
    "    decoded_splits = [tuple(tuple(sorted(tup)) for tup in pair) for pair in decoded_splits]\n",
    "    return tuple(decoded_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_factorial(n):\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * double_factorial(n - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "double_factorial((2*n-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "total_trees = double_factorial((2*n-3))\n",
    "labels = [i for i in range(n)]\n",
    "all_trees = []\n",
    "for i in range(total_trees):\n",
    "    all_trees.append(generate(n, labels=None, seed=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(all_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_all_bbok_splits(enc):\n",
    "    c = len(bin(enc)[2:])\n",
    "    a = np.arange(c, dtype=int)\n",
    "    rc = a[(1 << a & enc).astype(bool)]\n",
    "\n",
    "    if len(rc) == 1:\n",
    "        return [(1 << rc[0], 0)]\n",
    "\n",
    "    all_splits = []\n",
    "    for sub_id in range(1, np.power(2, len(rc) - 1)):\n",
    "        mask = format(sub_id, 'b').zfill(len(rc))\n",
    "        mask = np.array(list(mask), dtype=int)\n",
    "\n",
    "        c1_group = rc[mask.astype(bool)]\n",
    "        c2_group = np.setdiff1d(rc, c1_group)\n",
    "\n",
    "        all_splits.append((np.sum(1 << np.array(c1_group)), np.sum(1 << np.array(c2_group))))\n",
    "    \n",
    "    return all_splits\n",
    "\n",
    "def generate_all(n, labels=None):\n",
    "    all_ds = []  # all dichotomies\n",
    "    s = []  # stack\n",
    "    if labels is None:\n",
    "        labels = np.arange(n, dtype=int)\n",
    "    rc = np.sum([1 << i for i in labels])\n",
    "\n",
    "    root_splits = generate_all_bbok_splits(rc)\n",
    "    for root_split in root_splits:\n",
    "        s.append(([root_split], root_split))\n",
    "\n",
    "    while len(s) != 0:\n",
    "        current_dichotomy, split = s.pop()\n",
    "\n",
    "        if split[1] == 0:\n",
    "            decoded_splits = [decode_split(split, labels) for split in current_dichotomy]\n",
    "            decoded_splits = [tuple(tuple(sorted(tup)) for tup in pair) for pair in decoded_splits]\n",
    "            all_ds.append(tuple(decoded_splits))\n",
    "            continue\n",
    "\n",
    "        for split_0 in generate_all_bbok_splits(split[0]):\n",
    "            for split_1 in generate_all_bbok_splits(split[1]):\n",
    "                new_dichotomy = current_dichotomy + [split_0, split_1]\n",
    "                s.append((new_dichotomy, split_0))\n",
    "                s.append((new_dichotomy, split_1))\n",
    "    # print(all_ds)\n",
    "    # decoded_splits = [decode_split(split, labels) for split in s]\n",
    "    # decoded_splits = [tuple(tuple(sorted(tup)) for tup in pair) for pair in decoded_splits]\n",
    "\n",
    "    return all_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defined_all_trees(n: int):\n",
    "    \"\"\"\n",
    "    TODO remove this method and use something more rigourous. This function creates a list of all trees or combined models for a given \n",
    "    number of categories. \n",
    "    input:\n",
    "        n: number of categories/classes\n",
    "    output:\n",
    "        list of all trees\n",
    "    \"\"\"\n",
    "    categories = tuple(range(1, n+1))\n",
    "    all_trees_normalized = generate_normalized_branches(categories)\n",
    "\n",
    "    # Convert frozensets back to lists for readability\n",
    "    all_trees_normalized_list = [sorted(list(map(list, tree))) for tree in all_trees_normalized]\n",
    "    all_trees_normalized_list = [[sorted(branch, key=len, reverse=True) for branch in tree] for tree in all_trees_normalized_list]\n",
    "    return all_trees_normalized_list\n",
    "\n",
    "def stringify(node):\n",
    "    \"\"\" Convert a tuple of numbers into a concatenated string. \"\"\"\n",
    "    return node\n",
    "\n",
    "def generate_normalized_branches(categories):\n",
    "    \"\"\"\n",
    "    Recursively generate all branches for the given categories with normalized order.\n",
    "    This function ensures that each branch is represented in a standardized way to eliminate duplicates.\n",
    "    \"\"\"\n",
    "    if len(categories) <= 1:\n",
    "        return [set()]  # No branches can be formed from a single category\n",
    "\n",
    "    branches_set = set()\n",
    "    for left in generate_subsets(categories):\n",
    "        right = tuple(set(categories) - set(left))\n",
    "\n",
    "        # Generate branches for left and right subsets\n",
    "        left_branches = generate_normalized_branches(left)\n",
    "        right_branches = generate_normalized_branches(right)\n",
    "\n",
    "        for l_branch_set in left_branches:\n",
    "            for r_branch_set in right_branches:\n",
    "                # Combine current split with left and right branches\n",
    "                new_branch = tuple(sorted([left, right]))\n",
    "                combined_branches = {new_branch}.union(l_branch_set, r_branch_set)\n",
    "                branches_set.add(frozenset(combined_branches))  # Using frozenset to allow set of sets\n",
    "    return branches_set\n",
    "\n",
    "def generate_subsets(s):\n",
    "    \"\"\" Generate all non-empty subsets of a set s. \"\"\"\n",
    "    subsets = []\n",
    "    for r in range(1, len(s)):\n",
    "        subsets.extend(combinations(s, r))\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_defined = defined_all_trees(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees_defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_elements = set()\n",
    "\n",
    "for sublist in trees_defined:\n",
    "    lil_one = list()\n",
    "    for i in sublist:\n",
    "        lil_one.append(tuple(i))\n",
    "    unique_elements.add(tuple(lil_one))\n",
    "\n",
    "# Convert set back to list if needed\n",
    "unique_list = list(unique_elements)\n",
    "\n",
    "# Print unique elements\n",
    "print(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
